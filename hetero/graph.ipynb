{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed: 2328466898069313329\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "import csv\n",
    "\n",
    "# Set the random seed for PyTorch, NumPy, and random\n",
    "seed = 2328466898069313329\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Print the random seed\n",
    "print(f\"Random seed: {torch.initial_seed()}\")\n",
    "\n",
    "with open('../data/hetero_graph_data.pkl', \"rb\") as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "# Extract the data from the loaded dictionary\n",
    "data = loaded_data[\"hetero_graph\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'HeteroData' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/syyun/Dropbox (MIT)/gnnex/hetero/graph.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syyun/Dropbox%20%28MIT%29/gnnex/hetero/graph.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconvert\u001b[39;00m \u001b[39mimport\u001b[39;00m to_networkx\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/syyun/Dropbox%20%28MIT%29/gnnex/hetero/graph.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m networkx_data \u001b[39m=\u001b[39m to_networkx(data\u001b[39m=\u001b[39;49mdata, to_undirected\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pyg/lib/python3.8/site-packages/torch_geometric/utils/convert.py:132\u001b[0m, in \u001b[0;36mto_networkx\u001b[0;34m(data, node_attrs, edge_attrs, graph_attrs, to_undirected, remove_self_loops)\u001b[0m\n\u001b[1;32m    129\u001b[0m graph_attrs \u001b[39m=\u001b[39m graph_attrs \u001b[39mor\u001b[39;00m []\n\u001b[1;32m    131\u001b[0m values \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 132\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m data(\u001b[39m*\u001b[39;49m(node_attrs \u001b[39m+\u001b[39;49m edge_attrs \u001b[39m+\u001b[39;49m graph_attrs)):\n\u001b[1;32m    133\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_tensor(value):\n\u001b[1;32m    134\u001b[0m         value \u001b[39m=\u001b[39m value \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39mdim() \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m value\u001b[39m.\u001b[39msqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'HeteroData' object is not callable"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils.convert import to_networkx\n",
    "networkx_data = to_networkx(data=data, to_undirected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Node IDs have been assigned to each node type.\n",
      "HeteroData(\n",
      "  \u001b[1mcongressperson\u001b[0m={\n",
      "    num_nodes=2431,\n",
      "    node_id=[2431]\n",
      "  },\n",
      "  \u001b[1mcommittee\u001b[0m={\n",
      "    num_nodes=556,\n",
      "    node_id=[556]\n",
      "  },\n",
      "  \u001b[1mticker\u001b[0m={\n",
      "    num_nodes=4202,\n",
      "    node_id=[4202]\n",
      "  },\n",
      "  \u001b[1mbill\u001b[0m={\n",
      "    num_nodes=47767,\n",
      "    node_id=[47767]\n",
      "  },\n",
      "  \u001b[1mnaics\u001b[0m={\n",
      "    num_nodes=744,\n",
      "    node_id=[744]\n",
      "  },\n",
      "  \u001b[1m(congressperson, buy-sell, ticker)\u001b[0m={\n",
      "    edge_index=[2, 24675],\n",
      "    edge_attr=[24675, 2]\n",
      "  },\n",
      "  \u001b[1m(congressperson, assignment, committee)\u001b[0m={\n",
      "    edge_index=[2, 11698],\n",
      "    edge_attr=[11698, 2]\n",
      "  },\n",
      "  \u001b[1m(ticker, lobbies_on, bill)\u001b[0m={\n",
      "    edge_index=[2, 148487],\n",
      "    edge_attr=[148487, 2]\n",
      "  },\n",
      "  \u001b[1m(bill, assigned_to, committee)\u001b[0m={\n",
      "    edge_index=[2, 75626],\n",
      "    edge_attr=[75626, 2]\n",
      "  },\n",
      "  \u001b[1m(ticker, classified, naics)\u001b[0m={\n",
      "    edge_index=[2, 4147],\n",
      "    edge_attr=[4147, 2]\n",
      "  },\n",
      "  \u001b[1m(ticker, rev_buy-sell, congressperson)\u001b[0m={\n",
      "    edge_index=[2, 24675],\n",
      "    edge_attr=[24675, 2]\n",
      "  },\n",
      "  \u001b[1m(committee, rev_assignment, congressperson)\u001b[0m={\n",
      "    edge_index=[2, 11698],\n",
      "    edge_attr=[11698, 2]\n",
      "  },\n",
      "  \u001b[1m(bill, rev_lobbies_on, ticker)\u001b[0m={\n",
      "    edge_index=[2, 148487],\n",
      "    edge_attr=[148487, 2]\n",
      "  },\n",
      "  \u001b[1m(committee, rev_assigned_to, bill)\u001b[0m={\n",
      "    edge_index=[2, 75626],\n",
      "    edge_attr=[75626, 2]\n",
      "  },\n",
      "  \u001b[1m(naics, rev_classified, ticker)\u001b[0m={\n",
      "    edge_index=[2, 4147],\n",
      "    edge_attr=[4147, 2]\n",
      "  }\n",
      ")\n",
      "['congressperson', 'committee', 'ticker', 'bill', 'naics']\n",
      "Edge types: [('congressperson', 'buy-sell', 'ticker'), ('congressperson', 'assignment', 'committee'), ('ticker', 'lobbies_on', 'bill'), ('bill', 'assigned_to', 'committee'), ('ticker', 'classified', 'naics'), ('ticker', 'rev_buy-sell', 'congressperson'), ('committee', 'rev_assignment', 'congressperson'), ('bill', 'rev_lobbies_on', 'ticker'), ('committee', 'rev_assigned_to', 'bill'), ('naics', 'rev_classified', 'ticker')]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unique_tickers = loaded_data[\"unique_tickers\"]\n",
    "unique_congresspeople = loaded_data[\"unique_congresspeople\"]\n",
    "unique_committees = loaded_data[\"unique_committees\"]\n",
    "unique_bills = loaded_data[\"unique_bills\"]\n",
    "unique_naics = loaded_data[\"unique_naics\"]\n",
    "\n",
    "import torch\n",
    "\n",
    "# Check if a GPU is available and use it, otherwise use the CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# Assign consecutive indices to each node type\n",
    "data['congressperson'].node_id = torch.arange(len(unique_congresspeople))\n",
    "data['committee'].node_id = torch.arange(len(unique_committees))\n",
    "data['ticker'].node_id = torch.arange(len(unique_tickers))\n",
    "data['bill'].node_id = torch.arange(len(unique_bills))\n",
    "data['naics'].node_id = torch.arange(len(unique_naics))\n",
    "\n",
    "# Print the updated data\n",
    "print(\"Node IDs have been assigned to each node type.\")\n",
    "print(data)\n",
    "print(data.node_types)\n",
    "\n",
    "# Collect edge_types \n",
    "edge_types = []\n",
    "# Convert edge_index tensors to integer type (torch.long)\n",
    "for edge_type, edge_index in data.edge_index_dict.items():\n",
    "    data.edge_index_dict[edge_type] = edge_index.to(torch.long)\n",
    "    edge_types.append(edge_type)\n",
    "\n",
    "# in this way we can effectively remove the edges we don't want to use - like congressperson/buy-sell/ticker\n",
    "model_edge_types = [edge_type for edge_type in edge_types if edge_type not in [(\"congressperson\", \"buy-sell\", \"ticker\"), (\"ticker\", \"rev_buy-sell\", \"congressperson\")]]\n",
    "\n",
    "print(\"Edge types:\", edge_types)\n",
    "print(len(edge_types))\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "# For this, we first split the set of edges into\n",
    "# training (80%), validation (10%), and testing edges (10%).\n",
    "# Across the training edges, we use 70% of edges for message passing,\n",
    "# and 30% of edges for supervision.\n",
    "# We further want to generate fixed negative edges for evaluation with a ratio of 2:1.\n",
    "# Negative edges during training will be generated on-the-fly.\n",
    "# We can leverage the `RandomLinkSplit()` transform for this from PyG:\n",
    "\n",
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0,\n",
    "    num_test=0.1,\n",
    "    disjoint_train_ratio=0.3, # Across the training edges, we use 70% of edges for message passing, and 30% of edges for supervision.\n",
    "    neg_sampling_ratio=1.0,\n",
    "    add_negative_train_samples=True,\n",
    "    edge_types=(\"congressperson\", \"buy-sell\", \"ticker\"),\n",
    "    rev_edge_types=(\"ticker\", \"rev_buy-sell\", \"congressperson\"), \n",
    ")\n",
    "\n",
    "\n",
    "train_data, val_data, test_data = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mcongressperson\u001b[0m={\n",
       "    num_nodes=2431,\n",
       "    node_id=[2431]\n",
       "  },\n",
       "  \u001b[1mcommittee\u001b[0m={\n",
       "    num_nodes=556,\n",
       "    node_id=[556]\n",
       "  },\n",
       "  \u001b[1mticker\u001b[0m={\n",
       "    num_nodes=4202,\n",
       "    node_id=[4202]\n",
       "  },\n",
       "  \u001b[1mbill\u001b[0m={\n",
       "    num_nodes=47767,\n",
       "    node_id=[47767]\n",
       "  },\n",
       "  \u001b[1mnaics\u001b[0m={\n",
       "    num_nodes=744,\n",
       "    node_id=[744]\n",
       "  },\n",
       "  \u001b[1m(congressperson, buy-sell, ticker)\u001b[0m={\n",
       "    edge_index=[2, 15546],\n",
       "    edge_attr=[15546, 2],\n",
       "    edge_label=[13324],\n",
       "    edge_label_index=[2, 13324]\n",
       "  },\n",
       "  \u001b[1m(congressperson, assignment, committee)\u001b[0m={\n",
       "    edge_index=[2, 11698],\n",
       "    edge_attr=[11698, 2]\n",
       "  },\n",
       "  \u001b[1m(ticker, lobbies_on, bill)\u001b[0m={\n",
       "    edge_index=[2, 148487],\n",
       "    edge_attr=[148487, 2]\n",
       "  },\n",
       "  \u001b[1m(bill, assigned_to, committee)\u001b[0m={\n",
       "    edge_index=[2, 75626],\n",
       "    edge_attr=[75626, 2]\n",
       "  },\n",
       "  \u001b[1m(ticker, classified, naics)\u001b[0m={\n",
       "    edge_index=[2, 4147],\n",
       "    edge_attr=[4147, 2]\n",
       "  },\n",
       "  \u001b[1m(ticker, rev_buy-sell, congressperson)\u001b[0m={\n",
       "    edge_index=[2, 15546],\n",
       "    edge_attr=[15546, 2]\n",
       "  },\n",
       "  \u001b[1m(committee, rev_assignment, congressperson)\u001b[0m={\n",
       "    edge_index=[2, 11698],\n",
       "    edge_attr=[11698, 2]\n",
       "  },\n",
       "  \u001b[1m(bill, rev_lobbies_on, ticker)\u001b[0m={\n",
       "    edge_index=[2, 148487],\n",
       "    edge_attr=[148487, 2]\n",
       "  },\n",
       "  \u001b[1m(committee, rev_assigned_to, bill)\u001b[0m={\n",
       "    edge_index=[2, 75626],\n",
       "    edge_attr=[75626, 2]\n",
       "  },\n",
       "  \u001b[1m(naics, rev_classified, ticker)\u001b[0m={\n",
       "    edge_index=[2, 4147],\n",
       "    edge_attr=[4147, 2]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values after applying the transform\n",
    "transformed_edge_label = train_data[\"congressperson\", \"buy-sell\", \"ticker\"].edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13324"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_edge_label\n",
    "len(transformed_edge_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Define seed edges:\n",
    "edge_label_index = train_data[\"congressperson\", \"buy-sell\", \"ticker\"].edge_label_index\n",
    "edge_label = train_data[\"congressperson\", \"buy-sell\", \"ticker\"].edge_label\n",
    "edge_attr = train_data[\"congressperson\", \"buy-sell\", \"ticker\"].edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import LinkNeighborLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size 1\n"
     ]
    }
   ],
   "source": [
    "# In the first hop, we sample at most 20 neighbors.\n",
    "# In the second hop, we sample at most 10 neighbors.\n",
    "# In addition, during training, we want to sample negative edges on-the-fly with\n",
    "# a ratio of 2:1.\n",
    "# We can make use of the `loader.LinkNeighborLoader` from PyG:\n",
    "\n",
    "num_neigbors = [20, 10, 5]\n",
    "batch_size = 1\n",
    "print(\"batch_size\", batch_size)\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,\n",
    "    num_neighbors=num_neigbors,\n",
    "    edge_label_index=((\"congressperson\", \"buy-sell\", \"ticker\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "from model import BuySellLinkPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the HeteroData object named 'data'\n",
    "num_nodes_dict = {node_type: data[node_type].num_nodes for node_type in data.node_types}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'congressperson': 2431,\n",
       " 'committee': 556,\n",
       " 'ticker': 4202,\n",
       " 'bill': 47767,\n",
       " 'naics': 744}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'congressperson': 2431, 'committee': 556, 'ticker': 4202, 'bill': 47767, 'naics': 744}\n",
      "num_layers 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13324 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "'NeighborSampler' requires either 'pyg-lib' or 'torch-sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/syyun/Dropbox (MIT)/gnnex/hetero/llm.ipynb Cell 12\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/syyun/Dropbox%20%28MIT%29/gnnex/hetero/llm.ipynb#X14sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m total_accuracy \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/syyun/Dropbox%20%28MIT%29/gnnex/hetero/llm.ipynb#X14sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m total_auc_roc \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/syyun/Dropbox%20%28MIT%29/gnnex/hetero/llm.ipynb#X14sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm(train_loader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/syyun/Dropbox%20%28MIT%29/gnnex/hetero/llm.ipynb#X14sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pyg/lib/python3.8/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pyg/lib/python3.8/site-packages/torch_geometric/loader/base.py:36\u001b[0m, in \u001b[0;36mDataLoaderIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> 36\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform_fn(\u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator))\n",
      "File \u001b[0;32m~/anaconda3/envs/pyg/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/pyg/lib/python3.8/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/pyg/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/pyg/lib/python3.8/site-packages/torch_geometric/loader/link_loader.py:182\u001b[0m, in \u001b[0;36mLinkLoader.collate_fn\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Samples a subgraph from a batch of input nodes.\"\"\"\u001b[39;00m\n\u001b[1;32m    180\u001b[0m input_data: EdgeSamplerInput \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_data[index]\n\u001b[0;32m--> 182\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlink_sampler\u001b[39m.\u001b[39;49msample_from_edges(\n\u001b[1;32m    183\u001b[0m     input_data, neg_sampling\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mneg_sampling)\n\u001b[1;32m    185\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilter_per_worker:  \u001b[39m# Execute `filter_fn` in the worker process\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilter_fn(out)\n",
      "File \u001b[0;32m~/anaconda3/envs/pyg/lib/python3.8/site-packages/torch_geometric/sampler/neighbor_sampler.py:182\u001b[0m, in \u001b[0;36mNeighborSampler.sample_from_edges\u001b[0;34m(self, inputs, neg_sampling)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msample_from_edges\u001b[39m(\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39m, inputs: EdgeSamplerInput,\n\u001b[1;32m    180\u001b[0m     neg_sampling: Optional[NegativeSampling] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    181\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[SamplerOutput, HeteroSamplerOutput]:\n\u001b[0;32m--> 182\u001b[0m     \u001b[39mreturn\u001b[39;00m edge_sample(inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sample, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_nodes, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdisjoint,\n\u001b[1;32m    183\u001b[0m                        \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_time, neg_sampling)\n",
      "File \u001b[0;32m~/anaconda3/envs/pyg/lib/python3.8/site-packages/torch_geometric/sampler/neighbor_sampler.py:481\u001b[0m, in \u001b[0;36medge_sample\u001b[0;34m(inputs, sample_fn, num_nodes, disjoint, node_time, neg_sampling)\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[39mif\u001b[39;00m edge_label_time \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# Always disjoint.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m         seed_time_dict \u001b[39m=\u001b[39m {\n\u001b[1;32m    478\u001b[0m             input_type[\u001b[39m0\u001b[39m]: torch\u001b[39m.\u001b[39mcat([src_time, dst_time], dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m),\n\u001b[1;32m    479\u001b[0m         }\n\u001b[0;32m--> 481\u001b[0m out \u001b[39m=\u001b[39m sample_fn(seed_dict, seed_time_dict)\n\u001b[1;32m    483\u001b[0m \u001b[39m# Enhance `out` by label information ##################################\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[39mif\u001b[39;00m disjoint:\n",
      "File \u001b[0;32m~/anaconda3/envs/pyg/lib/python3.8/site-packages/torch_geometric/sampler/neighbor_sampler.py:259\u001b[0m, in \u001b[0;36mNeighborSampler._sample\u001b[0;34m(self, seed, seed_time, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m     num_sampled_nodes \u001b[39m=\u001b[39m num_sampled_edges \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 259\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m requires \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m                       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meither \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpyg-lib\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch-sparse\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    262\u001b[0m \u001b[39mif\u001b[39;00m num_sampled_edges \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m     num_sampled_edges \u001b[39m=\u001b[39m remap_keys(\n\u001b[1;32m    264\u001b[0m         num_sampled_edges,\n\u001b[1;32m    265\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_edge_type,\n\u001b[1;32m    266\u001b[0m     )\n",
      "\u001b[0;31mImportError\u001b[0m: 'NeighborSampler' requires either 'pyg-lib' or 'torch-sparse'"
     ]
    }
   ],
   "source": [
    "# Print the num_nodes_dict\n",
    "print(num_nodes_dict)\n",
    "\n",
    "# Instantiate the model\n",
    "num_layers = 2\n",
    "print(\"num_layers\", num_layers)\n",
    "# model = BuySellLinkPrediction(num_nodes_dict, embedding_dim=64, num_edge_features=2, out_channels=64, edge_types=edge_types, num_layers=num_layers).to(device)\n",
    "model = BuySellLinkPrediction(\n",
    "    num_nodes_dict,\n",
    "    embedding_dim=64,\n",
    "    num_edge_features=2,\n",
    "    out_channels=64,\n",
    "    edge_types=model_edge_types,\n",
    "    num_layers=num_layers,\n",
    ").to(device)\n",
    "\n",
    "# Training loop\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "epochs = 100\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), lr=0.005\n",
    ")  # You can set the learning rate (lr) as needed\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "scheduler = StepLR(\n",
    "    optimizer, step_size=10, gamma=0.1\n",
    ")  # Decay the learning rate by a factor of 0.1 every 10 epochs\n",
    "\n",
    "# Initialize a variable to keep track of the best test AUC-ROC score\n",
    "best_test_auc_roc = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    total_auc_roc = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
